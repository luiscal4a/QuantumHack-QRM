{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b10d599",
   "metadata": {},
   "source": [
    "# Test with 10 MI features and 30 MU points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a561a2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174e4462",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"85yAUHFmZ0iMdi3dXtoCEM2hMIHf7nAYObWesUYpd9kBmxkXqXt1wr83ArjCC/nG\"\n",
    "\n",
    "from iqm.qiskit_iqm import IQMProvider\n",
    "provider = IQMProvider(\"https://resonance.meetiqm.com/\", quantum_computer=\"garnet\",\n",
    "            token=token)\n",
    "backend = provider.get_backend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ba1cb9",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'dataset_graph7.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset_graph7.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Separate features and labels\u001b[39;00m\n\u001b[32m      5\u001b[39m X = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mloan_status\u001b[39m\u001b[33m'\u001b[39m]).values\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/QuantumHack-QRM/.venv_3_12/lib64/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/QuantumHack-QRM/.venv_3_12/lib64/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/QuantumHack-QRM/.venv_3_12/lib64/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/QuantumHack-QRM/.venv_3_12/lib64/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/github/QuantumHack-QRM/.venv_3_12/lib64/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'dataset_graph7.csv'"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"dataset_graph7.csv\")\n",
    "\n",
    "# Separate features and labels\n",
    "X = df.drop(columns=['loan_status']).values\n",
    "y = df['loan_status'].values\n",
    "\n",
    "# Split by percentage\n",
    "train_percentage = 0.8  # 80% train, 20% test\n",
    "X_train, X_test, train_labels, test_labels = train_test_split(\n",
    "    X, y, train_size=train_percentage, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Actual sizes after splitting\n",
    "train_size = X_train.shape[0]\n",
    "test_size = X_test.shape[0]\n",
    "\n",
    "# Optional: print shapes to check\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"train_labels shape:\", train_labels.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"test_labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e83d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty kernel matrix\n",
    "num_samples = np.shape(X_train)[0]\n",
    "kernel_matrix = np.full((num_samples, num_samples), np.nan)\n",
    "test_matrix = np.full((test_size, num_samples), np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ac90af",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from qiskit.circuit.library import zz_feature_map\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# fm = zz_feature_map(feature_dimension=np.shape(train_data)[1], entanglement='linear', reps=1)\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mqiskit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcircuit\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibrary\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m zz_feature_map\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m fm = zz_feature_map(feature_dimension=np.shape(\u001b[43mX_train\u001b[49m)[\u001b[32m1\u001b[39m],  entanglement=\u001b[33m\"\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m\"\u001b[39m, reps=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# from qiskit.circuit.library import zz_feature_map\n",
    "# fm = zz_feature_map(feature_dimension=np.shape(train_data)[1], entanglement='linear', reps=1)\n",
    " \n",
    "from qiskit.circuit.library import zz_feature_map, unitary_overlap\n",
    " \n",
    "fm = zz_feature_map(feature_dimension=np.shape(X_train)[1],  entanglement=\"linear\", reps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ab8a58",
   "metadata": {},
   "source": [
    "### Check noise on the diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd680fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_shots = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4523fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.transpiler.preset_passmanagers import generate_preset_pass_manager\n",
    "from qiskit import execute\n",
    "\n",
    "unitary1 = fm.assign_parameters(X_train[0])\n",
    "unitary2 = fm.assign_parameters(X_train[0])\n",
    "\n",
    "overlap_circ = unitary_overlap(unitary1, unitary2)\n",
    "overlap_circ.measure_all()\n",
    "\n",
    "\n",
    "pm_no_opt = generate_preset_pass_manager(\n",
    "    optimization_level=0,\n",
    "    backend=backend\n",
    ")\n",
    "circ_no_opt = pm_no_opt.run(overlap_circ)\n",
    "\n",
    "\n",
    "counts = (\n",
    "    backend.run(circ_no_opt, shots=num_shots)\n",
    "    .result()[0]\n",
    "    .data.meas.get_int_counts()\n",
    ")\n",
    "\n",
    "# Probability of measuring |0...0>\n",
    "p0 = counts.get('0' * circ_no_opt.num_qubits, 0) / num_shots\n",
    "\n",
    "print(\"Estimated K(x,x):\", p0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba7eb8a",
   "metadata": {},
   "source": [
    "### With pauli random noise and filling things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a128db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_ibm_runtime import Session, SamplerV2 as Sampler\n",
    "\n",
    "with Session(backend=backend) as session:\n",
    "    sampler = Sampler(mode=session)\n",
    "\n",
    "    sampler.options.dynamical_decoupling.enable = True\n",
    "    sampler.options.twirling.enable_gates = True\n",
    "\n",
    "    result = sampler.run(\n",
    "        [circ_no_opt],\n",
    "        shots=num_shots\n",
    "    ).result()\n",
    "\n",
    "    quasi = result.quasi_dists[0]\n",
    "    p0 = quasi.get(0, 0.0)\n",
    "    session.close()\n",
    "    \n",
    "print(\"Estimated K(x,x) with DD + twirling:\", p0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b504b",
   "metadata": {},
   "source": [
    "### Actual complete kernel matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ba436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit.primitives import StatevectorSampler, unitary_overlap\n",
    "from qiskit_ibm_runtime import Session, SamplerV2 as Sampler\n",
    "from qiskit import transpile\n",
    " \n",
    "# Open a Runtime session:\n",
    "session = Session(backend=backend)\n",
    "# Use sampler and get the counts\n",
    "\n",
    "sampler = Sampler(mode=session)\n",
    "options = sampler.options\n",
    "options.dynamical_decoupling.enable = True\n",
    "options.twirling.enable_gates = True\n",
    "\n",
    "for x1 in range(0, train_size):\n",
    "    for x2 in range(x1 + 1, train_size):\n",
    "        unitary1 = fm.assign_parameters(list(X_train[x1]) + [np.pi / 2])\n",
    "        unitary2 = fm.assign_parameters(list(X_train[x2]) + [np.pi / 2])\n",
    " \n",
    "        # Create the overlap circuit\n",
    "        overlap_circ = unitary_overlap(unitary1, unitary2)\n",
    "        overlap_circ.measure_all()\n",
    "\n",
    "        print(\"circuit depth = \", overlap_circ.decompose().depth())\n",
    "        #overlap_circ.decompose().draw(\"mpl\", scale=0.6, style=\"iqp\")\n",
    "        print(\n",
    "            \"two-qubit depth\",\n",
    "            overlap_circ.decompose().depth(lambda instr: len(instr.qubits) > 1),\n",
    "        )\n",
    "\n",
    "        # Use sampler and get the counts\n",
    "\n",
    "        # Transpile and run the circuit on an IQM backend\n",
    "        qc_transpiled = transpile( overlap_circ, optimization_level=3, backend=backend)\n",
    "        print(\"circuit depth = \", qc_transpiled.decompose().depth())\n",
    "        print(\n",
    "            \"two-qubit depth\",\n",
    "            qc_transpiled.decompose().depth(lambda instr: len(instr.qubits) > 1),\n",
    "        )\n",
    "        #qc_transpiled.draw(\"mpl\")\n",
    "\n",
    " \n",
    "        counts = (\n",
    "            sampler.run([qc_transpiled], shots=num_shots).result()[0].data.meas.get_int_counts()\n",
    "        )\n",
    " \n",
    "        # Assign the probability of the 0 state to the kernel matrix, and the transposed element (since this is an inner product)\n",
    "        kernel_matrix[x1, x2] = counts.get(0, 0.0) / num_shots\n",
    "        kernel_matrix[x2, x1] = counts.get(0, 0.0) / num_shots\n",
    "    # Fill in on-diagonal elements with 1, again, since this is an inner-product corresponding to probability (or alter the code to check these entries and verify they yield 1)\n",
    "    kernel_matrix[x1, x1] = 1\n",
    " \n",
    "# Close session after done\n",
    "session.close()\n",
    "print(\"training done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a84d66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Similar process to above, but for testing data.\n",
    "for x1 in range(0, test_size):\n",
    "    for x2 in range(0, train_size):\n",
    "        unitary1 = fm.assign_parameters(list(X_test[x1]) + [np.pi / 2])\n",
    "        unitary2 = fm.assign_parameters(list(X_test[x2]) + [np.pi / 2])\n",
    " \n",
    "        # Create the overlap circuit\n",
    "        overlap_circ = unitary_overlap(unitary1, unitary2)\n",
    "        overlap_circ.measure_all()\n",
    "        \n",
    "        qc_transpiled = transpile( overlap_circ, optimization_level=3, backend=backend)\n",
    "\n",
    "        counts = (\n",
    "            backend.run([], shots=num_shots)\n",
    "            .result()[0]\n",
    "            .data.meas.get_int_counts()\n",
    "        )\n",
    " \n",
    "        test_matrix[x1, x2] = counts.get(0, 0.0) / num_shots\n",
    " \n",
    "print(\"test matrix done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c02b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as NumPy files\n",
    "np.save(\"kernel_matrix_quantum.npy\", kernel_matrix)\n",
    "np.save(\"test_matrix_quantum.npy\", test_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ca329ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a support vector classifier from a classical ML package.\n",
    "from sklearn.svm import SVC\n",
    " \n",
    "# Specify that you want to use a pre-computed kernel matrix\n",
    "qml_svc = SVC(kernel=\"precomputed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339893bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feed in the pre-computed matrix and the labels of the training data. The classical algorithm gives you a fit.\n",
    "qml_svc.fit(kernel_matrix, train_labels)\n",
    "\n",
    "# Now use the .score to test your data, using the matrix of test data, and test labels as your inputs.\n",
    "qml_score_precomputed_kernel = qml_svc.score(test_matrix, test_labels)\n",
    "print(f\"Precomputed kernel classification test score: {qml_score_precomputed_kernel}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efebc36",
   "metadata": {},
   "source": [
    "### Classical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4877a20",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m linear_svc = SVC(kernel=\u001b[33m'\u001b[39m\u001b[33mlinear\u001b[39m\u001b[33m'\u001b[39m, C=\u001b[32m1.0\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Train on your training data\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m linear_svc.fit(\u001b[43mX_train\u001b[49m, train_labels)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Predict on test data\u001b[39;00m\n\u001b[32m     11\u001b[39m y_pred = linear_svc.predict(X_test)\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Classical linear SVM\n",
    "linear_svc = SVC(kernel='linear', C=1.0)\n",
    "\n",
    "# Train on your training data\n",
    "linear_svc.fit(X_train, train_labels)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = linear_svc.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(\"Linear SVM accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_3_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
